{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne9gkpxi33gP"
      },
      "source": [
        "# Logistic Regression with scikit-learn\n",
        "\n",
        "## Introduction\n",
        "Logistic Regression is a **supervised learning** algorithm used primarily for **binary classification** (though it can be extended to multi-class problems). Despite the name \"regression,\" logistic regression is actually used for classification tasks.\n",
        "\n",
        "### How it Works\n",
        "- **Linear Model**: Logistic Regression starts with a linear combination of input features \\(x_1, x_2, \\dots, x_n\\). It computes a linear predictor \\(z = w_1 x_1 + w_2 x_2 + ... + w_n x_n + b\\).\n",
        "- **Sigmoid Function**: Instead of using this \\(z\\) directly, logistic regression feeds \\(z\\) through the sigmoid (logistic) function \\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\). The output is a number between 0 and 1, which can be interpreted as a **probability** of belonging to the positive class.\n",
        "\n",
        "### Why Use Logistic Regression?\n",
        "- It is easy to implement and interpret.\n",
        "- It provides probabilities directly (i.e., it can give you the chance that a sample is in one class vs. another).\n",
        "- Works well for linearly separable data (and can be extended with regularization or polynomial features).\n",
        "\n",
        "In this notebook, we will:\n",
        "1. Load a dataset (Iris dataset from scikit-learn).\n",
        "2. Explore basic features.\n",
        "3. Apply a Logistic Regression model.\n",
        "4. Evaluate our model's performance.\n",
        "\n",
        "## scikit-learn (sklearn) Library\n",
        "- **scikit-learn** is one of the most popular machine learning libraries in Python.\n",
        "- It provides tools for model training, evaluation, and data preprocessing.\n",
        "- The `LogisticRegression` class is part of `sklearn.linear_model`.\n",
        "\n",
        "Let's get started!"
      ],
      "id": "Ne9gkpxi33gP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEQiizWh33gU"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "print(\"Feature names:\", iris.feature_names)\n",
        "print(\"Target names:\", iris.target_names)\n",
        "print(\"First 5 rows of X:\\n\", X[:5])\n",
        "print(\"First 5 labels of y:\\n\", y[:5])"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "TEQiizWh33gU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqSXRjHz33gW"
      },
      "source": [
        "### Train/Test Split\n",
        "We'll split the Iris dataset into **training** and **testing** sets. A common split is 80% for training and 20% for testing, but any ratio can be used (like 70%-30%, 75%-25%, etc.)."
      ],
      "id": "sqSXRjHz33gW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYCOgQLv33gX"
      },
      "source": [
        "# 2. Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y)\n",
        "\n",
        "print(\"Train set size:\", X_train.shape)\n",
        "print(\"Test set size: \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "qYCOgQLv33gX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TvDFN2133gY"
      },
      "source": [
        "### Training the Logistic Regression Model\n",
        "We create an instance of `LogisticRegression` and fit it on our training data (`X_train` and `y_train`)."
      ],
      "id": "0TvDFN2133gY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odr1RsNp33gY"
      },
      "source": [
        "# 3. Train Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "print(\"Logistic Regression trained!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "odr1RsNp33gY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G35nvMw33gZ"
      },
      "source": [
        "### Model Evaluation\n",
        "After training, we'll use the model to predict on the **test** set and measure how well it performs.\n",
        "\n",
        "Common metrics include:\n",
        "- **Accuracy**: Percentage of correct predictions.\n",
        "- **Confusion Matrix**: A grid showing counts of actual vs. predicted labels.\n",
        "- **Precision, Recall, F1-Score**: Detailed classification performance per class."
      ],
      "id": "8G35nvMw33gZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqxtb5_x33gZ"
      },
      "source": [
        "# 4. Predictions on the test set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "mqxtb5_x33gZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O4I3vYT33ga"
      },
      "source": [
        "## Observations\n",
        "- The **accuracy** here is often quite high on the Iris dataset because it's a relatively easy classification task.\n",
        "- The **confusion matrix** helps to see which classes are confused with each other.\n",
        "- The **classification report** shows precision, recall, and F1-score for each class.\n",
        "\n",
        "## Next Steps\n",
        "- Experiment with **different test sizes** or **different random states**.\n",
        "- Try adding **regularization parameters** or other hyperparameters (like `C`, `penalty`) in the `LogisticRegression` model.\n",
        "- Consider using **pipelines** for preprocessing steps (like scaling or feature engineering) if you have more complex data.\n",
        "\n",
        "### Conclusion\n",
        "In this notebook, we demonstrated how to use **Logistic Regression** from **scikit-learn** to classify the Iris dataset. We covered:\n",
        "1. Loading the dataset.\n",
        "2. Splitting into train and test sets.\n",
        "3. Training a logistic regression model.\n",
        "4. Evaluating the model with accuracy, confusion matrix, and a classification report.\n",
        "\n",
        "Logistic regression remains a strong baseline and a fundamental model in machine learning, especially for classification problems."
      ],
      "id": "0O4I3vYT33ga"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}